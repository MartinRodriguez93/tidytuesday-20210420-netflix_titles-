#Analyze if duration of the movies/tv shows increased or decreased over the years

#Remove movies/tv shows with season/seasons as duration_list_unit:
nf_titles_min=nf_titles_df_final.loc[nf_titles_df_final['duration_list_unit']=='min',:]

#Avg duration per year:
nf_titles_min=nf_titles_min.groupby(['year_added'],as_index = False)['duration_list_q'].mean()

avg_min_line=px.line(data_frame=nf_titles_min,
             x='year_added',
             y='duration_list_q',
             title="Avg movies/tv shows duration per year",
             labels={'duration_list_q':'Duration in minutes',
                     'year_added':'Year'})
avg_min_line.update_traces(hovertemplate='<b>Year: </b>%{x}<br><b>Avg. duration (min): </b>%{y}')

---------------------------------------------------------------------------------------------------------------

#Analyze duration of the movies/tv shows between top 5 countries

#Remove movies/tv shows with season/seasons as duration_list_unit:
nf_titles_min_country=nf_titles_df_final.loc[nf_titles_df_final['duration_list_unit']=='min',:]

#Avg duration per year:
nf_titles_min_country=nf_titles_min_country.groupby(['country','year_added'],as_index = False)['duration_list_q'].mean()
nf_titles_min_country=nf_titles_min_country.loc[nf_titles_min_country['country'].isin(top5_countries),:]
nf_titles_min_country=nf_titles_min_country.sort_values('year_added')

#Line
avg_min_line_country=px.line(data_frame=nf_titles_min_country,
                     x='year_added',
                     y='duration_list_q',
                     color='country',        
                     title="Avg movies/tv shows duration per year per country",
                     labels={'duration_list_q':'Duration in minutes',
                             'year_added':'Year'})
avg_min_line_country.update_traces(hovertemplate='<b>Year: </b>%{x}<br><b>Avg. duration (min): </b>%{y}')
avg_min_line_country.update_layout(legend=dict(
                            yanchor="top",
                            y=0.99,
                            xanchor="left",
                            x=0.01)
                     )
                     
---------------------------------------------------------------------------------------------------------------

#Number of movies/tv shows per director:

#Quantity of movies/tvshows per director:
df_shows_director=nf_df_ex_director2.groupby(['director'],as_index = False)['show_id'].count().sort_values('show_id',ascending=False)

#Replace countries with Nan values of movies/tvshows: 
df_shows_director['director']=df_shows_director['director'].fillna(0)

#% over total column: df_shows_country['perc_over_total']
df_shows_director['perc_over_total']=df_shows_director['show_id']/sum(df_shows_director['show_id'])

#Top 10 share of total movies_tvshows: 2,5%
sum(df_shows_director['perc_over_total'][:10])

df_shows_director.describe()

---------------------------------------------------------------------------------------------------------------

#Share of rating over total movies/tv shows:

#Quantity of movies/tv shows per rating:
df_shows_rating=(nf_titles_df_final
                                   .groupby('rating',as_index = False)['show_id']
                                   .count()
                                   .sort_values('show_id',ascending=False)
                                   .reset_index(drop=True)
)

#Pie:
pie_shows_rating=px.pie(data_frame=df_shows_rating,
       names='rating',
       values='show_id',
       title='Share of rating over total movies/tv shows')
pie_shows_rating.update_traces(hovertemplate='<b>Rating: </b>%{label}<br><b>Quantity: </b>%{value}')
pie_shows_rating.show()

---------------------------------------------------------------------------------------------------------------

#Wordcloud of listed_in:

#Quantity of movies/tv shows per class:
df_shows_listed_in=(nf_df_ex_listed_in
                                      .groupby('listed_in',as_index = False)['show_id']
                                      .count()
                                      .sort_values('show_id',ascending=False)
                                      .reset_index(drop=True)
)

#Replace blanks from column listed_in
df_shows_listed_in['listed_in']=[i.replace(' ','').replace('&','').replace('-','') for i in df_shows_listed_in['listed_in']]

#Unigram for WordCloud (each class times its quantity):
unigram_shows_listed_in=sum([[s] * n for s, n in zip(list(df_shows_listed_in['listed_in']),
                                                     list(df_shows_listed_in['show_id']))
                            ],
                                                     []
                           )

#Check unigram len (should be 0:)
len(unigram_shows_listed_in)-sum(list(df_shows_listed_in['show_id']))

#listed_in WordCloud:
plt.figure(figsize=(20,10))
wordcloud=WordCloud(width=2000,
                    height=1000,
                    max_font_size=200,
                    max_words=100,
                    random_state=1,
                    background_color='white',
                    collocations=False,
                    colormap='Set2',#Source: https://matplotlib.org/stable/tutorials/colors/colormaps.html
                   ).generate(' '.join(unigram_shows_listed_in))
plt.imshow(wordcloud)
plt.axis('off')
plt.show()
